"""
HeartLib Gradio Interface
A web-based interface for music generation using HeartMuLaGenPipeline.
"""

import os
import sys
import gc
import time
import torch
import gradio as gr
from datetime import datetime

# Add the src directory to path for imports
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "src"))

from heartlib import HeartMuLaGenPipeline


# ============================================================================
# Configuration
# ============================================================================

DEFAULT_MODEL_PATH = "./ckpt"
OUTPUT_DIR = "./output"
FFMPEG_DIR = "./ffmpeg/bin"  # Local ffmpeg directory


def setup_ffmpeg_path():
    """
    Add local ffmpeg bin directory to PATH if it exists.
    This allows bundling ffmpeg with the application without system-wide installation.
    """
    script_dir = os.path.dirname(os.path.abspath(__file__))
    ffmpeg_bin_path = os.path.join(script_dir, FFMPEG_DIR)
    
    if os.path.exists(ffmpeg_bin_path):
        # Add to PATH (prepend to take priority over system ffmpeg)
        os.environ["PATH"] = ffmpeg_bin_path + os.pathsep + os.environ.get("PATH", "")
        print(f"âœ… FFmpeg è·¯å¾‘å·²è¨­å®š: {ffmpeg_bin_path}")
        return True
    else:
        print(f"âš ï¸ FFmpeg ç›®éŒ„ä¸å­˜åœ¨: {ffmpeg_bin_path}")
        print("   è«‹å°‡ ffmpeg çš„ bin è³‡æ–™å¤¾æ”¾ç½®æ–¼ ./ffmpeg/bin/")
        return False


# Initialize ffmpeg path on module load
setup_ffmpeg_path()


def get_available_devices():
    """
    Detect available compute devices (CPU and CUDA GPUs).
    
    Returns:
        list: List of device strings like ['cpu', 'cuda:0', 'cuda:1', ...]
    """
    devices = ["cpu"]
    if torch.cuda.is_available():
        for i in range(torch.cuda.device_count()):
            gpu_name = torch.cuda.get_device_name(i)
            devices.append(f"cuda:{i} ({gpu_name})")
    return devices


def parse_device_string(device_str: str) -> str:
    """
    Parse device string to extract the device identifier.
    
    Args:
        device_str: Device string like 'cuda:0 (NVIDIA RTX 4090)'
    
    Returns:
        str: Clean device string like 'cuda:0'
    """
    if "(" in device_str:
        return device_str.split(" (")[0]
    return device_str


# ============================================================================
# Throttled Progress Tracking
# ============================================================================

class ThrottledTqdmProgress:
    """
    A context manager that patches tqdm to update Gradio progress at reduced frequency.
    This avoids the overhead of updating on every iteration while still showing progress.
    """
    
    def __init__(self, progress_callback, update_interval: int = 50):
        """
        Args:
            progress_callback: Gradio progress function
            update_interval: Only update progress every N iterations
        """
        self.progress = progress_callback
        self.update_interval = update_interval
        self._original_tqdm = None
    
    def __enter__(self):
        import tqdm as tqdm_module
        self._original_tqdm = tqdm_module.tqdm
        
        progress = self.progress
        update_interval = self.update_interval
        
        class ThrottledTqdm(self._original_tqdm):
            def __init__(self, *args, **kwargs):
                super().__init__(*args, **kwargs)
                self._gradio_update_counter = 0
                self._last_progress_update = 0
            
            def update(self, n=1):
                result = super().update(n)
                self._gradio_update_counter += n
                
                # Only update Gradio progress every N iterations
                if self.total and self._gradio_update_counter >= update_interval:
                    current_progress = self.n / self.total
                    # Calculate speed
                    elapsed = self.format_dict.get('elapsed', 0)
                    rate = self.n / elapsed if elapsed > 0 else 0
                    
                    progress(
                        current_progress,
                        desc=f"ç”Ÿæˆä¸­... {self.n}/{self.total} ({rate:.1f} it/s)"
                    )
                    self._gradio_update_counter = 0
                
                return result
        
        # Patch tqdm globally
        tqdm_module.tqdm = ThrottledTqdm
        
        # Also patch the tqdm import in heartlib if it's already imported
        try:
            from heartlib.pipelines import music_generation
            music_generation.tqdm = ThrottledTqdm
        except:
            pass
        
        return self
    
    def __exit__(self, *args):
        import tqdm as tqdm_module
        tqdm_module.tqdm = self._original_tqdm
        
        # Restore original in heartlib
        try:
            from heartlib.pipelines import music_generation
            music_generation.tqdm = self._original_tqdm
        except:
            pass


# ============================================================================
# Music Generation Function
# ============================================================================

def generate_music(
    lyrics: str,
    tags: str,
    max_audio_length_sec: int,
    topk: int,
    temperature: float,
    cfg_scale: float,
    model_version: str,
    mula_device: str,
    codec_device: str,
    mula_dtype: str,
    codec_dtype: str,
    lazy_load: bool,
    progress=gr.Progress(),
):
    """
    Generate music using HeartMuLaGenPipeline with progress tracking.
    
    Args:
        lyrics: Song lyrics text
        tags: Comma-separated music style tags
        max_audio_length_sec: Maximum audio length in seconds
        topk: Top-K sampling parameter
        temperature: Sampling temperature
        cfg_scale: Classifier-free guidance scale
        model_version: Model version (e.g., "3B")
        mula_device: Device for MuLa model
        codec_device: Device for codec model
        mula_dtype: Data type for MuLa model
        codec_dtype: Data type for codec model
        lazy_load: Whether to use lazy loading
        progress: Gradio progress tracker
    
    Returns:
        tuple: (audio_path, log_output)
    """
    log_lines = []
    
    def log(msg):
        """Add message to log and print to console."""
        log_lines.append(msg)
        print(msg)
    
    # Validate inputs
    if not lyrics.strip():
        return None, "âŒ éŒ¯èª¤ï¼šè«‹è¼¸å…¥æ­Œè©"
    
    if not tags.strip():
        return None, "âŒ éŒ¯èª¤ï¼šè«‹è¼¸å…¥éŸ³æ¨‚æ¨™ç±¤"
    
    output_path = None
    
    try:
        # Parse devices
        mula_dev = torch.device(parse_device_string(mula_device))
        codec_dev = torch.device(parse_device_string(codec_device))
        
        # Parse dtypes
        dtype_map = {
            "bfloat16": torch.bfloat16,
            "float16": torch.float16,
            "float32": torch.float32,
        }
        mula_dt = dtype_map.get(mula_dtype, torch.bfloat16)
        codec_dt = dtype_map.get(codec_dtype, torch.float32)
        
        log(f"ğŸµ é–‹å§‹éŸ³æ¨‚ç”Ÿæˆ...")
        log(f"ğŸ“ æ­Œè©é•·åº¦: {len(lyrics)} å­—ç¬¦")
        log(f"ğŸ·ï¸  æ¨™ç±¤: {tags}")
        log(f"âš™ï¸  åƒæ•¸: é•·åº¦={max_audio_length_sec}s, topk={topk}, temp={temperature}, cfg={cfg_scale}")
        log(f"ğŸ–¥ï¸  è£ç½®: MuLa={mula_dev}, Codec={codec_dev}")
        log(f"ğŸ“Š é¡å‹: MuLa={mula_dtype}, Codec={codec_dtype}")
        log(f"ğŸ’¾ Lazy Load: {'å•Ÿç”¨' if lazy_load else 'åœç”¨'}")
        log("-" * 50)
        
        # Create output directory
        os.makedirs(OUTPUT_DIR, exist_ok=True)
        
        # Generate output filename with timestamp
        timestamp = datetime.now().strftime("%Y_%m_%d_%H%M%S")
        output_path = os.path.join(OUTPUT_DIR, f"{timestamp}.mp3")
        
        # Load pipeline
        progress(0.0, desc="è¼‰å…¥æ¨¡å‹ä¸­...")
        log("ğŸ”„ è¼‰å…¥æ¨¡å‹ä¸­...")
        
        pipe = HeartMuLaGenPipeline.from_pretrained(
            DEFAULT_MODEL_PATH,
            device={
                "mula": mula_dev,
                "codec": codec_dev,
            },
            dtype={
                "mula": mula_dt,
                "codec": codec_dt,
            },
            version=model_version,
            lazy_load=lazy_load,
        )
        log("âœ… æ¨¡å‹è¼‰å…¥å®Œæˆ")
        
        # Convert seconds to milliseconds
        max_audio_length_ms = max_audio_length_sec * 1000
        max_frames = max_audio_length_ms // 80  # Each frame is 80ms
        
        # Generate music with time tracking
        progress(0.1, desc="ç”ŸæˆéŸ³æ¨‚ä¸­...")
        log("ğŸ¼ ç”ŸæˆéŸ³æ¨‚ä¸­...")
        log(f"ğŸ“Š æœ€å¤§å¹€æ•¸: {max_frames} frames")
        
        start_time = time.time()
        
        # Use throttled progress to avoid overhead (updates every 50 iterations)
        with ThrottledTqdmProgress(progress, update_interval=50):
            with torch.no_grad():
                pipe(
                    {
                        "lyrics": lyrics,
                        "tags": tags,
                    },
                    max_audio_length_ms=max_audio_length_ms,
                    save_path=output_path,
                    topk=topk,
                    temperature=temperature,
                    cfg_scale=cfg_scale,
                )
        
        end_time = time.time()
        elapsed_time = end_time - start_time
        avg_speed = max_frames / elapsed_time if elapsed_time > 0 else 0
        
        progress(1.0, desc="å®Œæˆï¼")
        log("-" * 50)
        log(f"âœ… ç”Ÿæˆå®Œæˆï¼")
        log(f"â±ï¸  ç¸½è€—æ™‚: {elapsed_time:.2f} ç§’")
        log(f"âš¡ å¹³å‡é€Ÿåº¦: {avg_speed:.2f} frames/s")
        log(f"ğŸ“ è¼¸å‡ºæª”æ¡ˆ: {output_path}")
        
        # Cleanup
        del pipe
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        return output_path, "\n".join(log_lines)
        
    except Exception as e:
        error_msg = f"âŒ ç”Ÿæˆå¤±æ•—: {str(e)}"
        log(error_msg)
        import traceback
        log(traceback.format_exc())
        return None, "\n".join(log_lines)


# ============================================================================
# Gradio Interface
# ============================================================================

def create_interface():
    """Create and configure the Gradio interface."""
    
    # Get available devices
    devices = get_available_devices()
    default_device = devices[1] if len(devices) > 1 else devices[0]  # Prefer first GPU
    
    # Sample lyrics
    sample_lyrics = """[Intro]

[Verse]
é™½å…‰ç‘è½åœ¨çª—å°ä¸Š
æ–°çš„ä¸€å¤©é–‹å§‹é–ƒäº®
å¿ƒä¸­æœ‰å¤¢æƒ³è¦é£›ç¿”
è®“éŸ³æ¨‚å¸¶æˆ‘å»é æ–¹

[Chorus]
å”±å‡ºå¿ƒä¸­çš„æ—‹å¾‹
è®“å¿«æ¨‚å‚³é
æ¯ä¸€å€‹éŸ³ç¬¦éƒ½æ˜¯å¥‡è¹Ÿ
é€™å°±æ˜¯æˆ‘çš„éŸ³æ¨‚ä¹‹æ—…

[Outro]
(æ¼¸æ¼¸æ·¡å‡º...)"""

    sample_tags = "pop,piano,upbeat,cheerful,female voice"
    
    # Build interface
    with gr.Blocks(
        title="HeartLib Music Generation",
        theme=gr.themes.Soft(),
        css="""
        .main-title { text-align: center; margin-bottom: 1rem; }
        .log-box textarea { 
            font-family: 'Consolas', 'Monaco', 'Courier New', monospace !important; 
            font-size: 13px !important;
            line-height: 1.5 !important;
        }
        """
    ) as demo:
        gr.Markdown(
            """
            # ğŸµ HeartLib Music Generation
            ä½¿ç”¨ AI æ ¹æ“šæ­Œè©å’Œé¢¨æ ¼æ¨™ç±¤ç”ŸæˆéŸ³æ¨‚
            """,
            elem_classes=["main-title"]
        )
        
        with gr.Row():
            # Left column - Inputs
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“ è¼¸å…¥")
                
                lyrics_input = gr.Textbox(
                    label="æ­Œè©",
                    placeholder="è¼¸å…¥æ­Œè©ï¼Œå¯ä½¿ç”¨ [Intro], [Verse], [Chorus] ç­‰æ¨™è¨˜...",
                    lines=12,
                    value=sample_lyrics,
                )
                
                tags_input = gr.Textbox(
                    label="éŸ³æ¨‚æ¨™ç±¤",
                    placeholder="ä¾‹å¦‚: pop, rock, piano, upbeat, male voice",
                    value=sample_tags,
                )
                
                gr.Markdown("### âš™ï¸ åƒæ•¸è¨­å®š")
                
                with gr.Row():
                    max_length = gr.Slider(
                        label="éŸ³è¨Šé•·åº¦ (ç§’)",
                        minimum=30,
                        maximum=360,
                        value=240,
                        step=10,
                    )
                    
                    topk = gr.Slider(
                        label="Top-K",
                        minimum=1,
                        maximum=100,
                        value=50,
                        step=1,
                    )
                
                with gr.Row():
                    temperature = gr.Slider(
                        label="Temperature",
                        minimum=0.1,
                        maximum=2.0,
                        value=1.0,
                        step=0.1,
                    )
                    
                    cfg_scale = gr.Slider(
                        label="CFG Scale",
                        minimum=1.0,
                        maximum=3.0,
                        value=1.5,
                        step=0.1,
                    )
                
                gr.Markdown("### ğŸ–¥ï¸ è£ç½®è¨­å®š")
                
                model_version = gr.Dropdown(
                    label="æ¨¡å‹ç‰ˆæœ¬",
                    choices=["3B"],
                    value="3B",
                )
                
                with gr.Row():
                    mula_device = gr.Dropdown(
                        label="MuLa è£ç½®",
                        choices=devices,
                        value=default_device,
                    )
                    
                    codec_device = gr.Dropdown(
                        label="Codec è£ç½®",
                        choices=devices,
                        value=default_device,
                    )
                
                with gr.Row():
                    mula_dtype = gr.Dropdown(
                        label="MuLa è³‡æ–™é¡å‹",
                        choices=["bfloat16", "float16", "float32"],
                        value="bfloat16",
                        info="bf16ï¼šæ•ˆèƒ½è¼ƒä½³ï¼Œè¨˜æ†¶é«”ç”¨é‡è¼ƒä½",
                    )
                    
                    codec_dtype = gr.Dropdown(
                        label="Codec è³‡æ–™é¡å‹",
                        choices=["bfloat16", "float16", "float32"],
                        value="float32",
                        info="fp32ï¼šéŸ³è³ªè¼ƒä½³ã€‚ä½¿ç”¨ bf16 å¯èƒ½é™ä½éŸ³è³ª",
                    )
                
                lazy_load = gr.Checkbox(
                    label="Lazy Loadï¼ˆå»¶é²è¼‰å…¥ï¼‰",
                    value=True,
                    info="å•Ÿç”¨å¾Œæ¨¡çµ„å°‡æŒ‰éœ€è¼‰å…¥ï¼Œå¯ç¯€çœ GPU è¨˜æ†¶é«”",
                )
                
                generate_btn = gr.Button("ğŸµ ç”ŸæˆéŸ³æ¨‚", variant="primary", size="lg")
            
            # Right column - Outputs
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ§ è¼¸å‡º")
                
                audio_output = gr.Audio(
                    label="ç”Ÿæˆçš„éŸ³æ¨‚",
                    type="filepath",
                )
                
                gr.Markdown("### ğŸ“‹ åŸ·è¡Œæ—¥èªŒ")
                
                log_output = gr.Textbox(
                    label="æ—¥èªŒè¼¸å‡º",
                    lines=20,
                    max_lines=30,
                    interactive=False,
                    elem_classes=["log-box"],
                )
        
        # Connect the generate button
        generate_btn.click(
            fn=generate_music,
            inputs=[
                lyrics_input,
                tags_input,
                max_length,
                topk,
                temperature,
                cfg_scale,
                model_version,
                mula_device,
                codec_device,
                mula_dtype,
                codec_dtype,
                lazy_load,
            ],
            outputs=[audio_output, log_output],
        )
    
    return demo


# ============================================================================
# Main Entry Point
# ============================================================================

if __name__ == "__main__":
    print("ğŸš€ å•Ÿå‹• HeartLib Gradio ä»‹é¢...")
    print(f"ğŸ“ è¼¸å‡ºç›®éŒ„: {os.path.abspath(OUTPUT_DIR)}")
    
    # Create output directory
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # Create and launch interface
    demo = create_interface()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        inbrowser=True,
    )
